{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text for model training (SMS messages)\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'Please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "bow=vect.fit_transform(simple_train)\n",
    "\n",
    "# examine the fitted vocabulary\n",
    "features=vect.get_feature_names()\n",
    "# bow\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(bow.toarray(), columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 1)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "print(type(bow))\n",
    "\n",
    "# examine the sparse matrix contents\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read file into pandas using a relative path\n",
    "df = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "df.dropna(how=\"any\", inplace=True, axis=1)\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "df.head()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message\n",
       "label         \n",
       "ham       4825\n",
       "spam       747"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 4825 ham message and 747 spam message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  label_num\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...          1\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?          0\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...          0\n",
       "5570   ham  The guy did some bitching but I acted like i'd...          0\n",
       "5571   ham                         Rofl. Its true to its name          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_num']=df.label.map({'ham':0,\"spam\":1})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0   \n",
       "1   ham                      Ok lar... Joking wif u oni...          0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "3   ham  U dun say so early hor... U c already then say...          0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "\n",
       "   message_len  \n",
       "0          111  \n",
       "1           29  \n",
       "2          155  \n",
       "3           49  \n",
       "4           61  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['message_len'] = df.message.apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Message Length')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "df[df.label=='ham'].message_len.plot(bins=30, kind='hist', color='blue', \n",
    "                                       label='Ham messages', alpha=0.5)\n",
    "df[df.label=='spam'].message_len.plot( kind='hist', color='red', \n",
    "                                       label='Spam messages', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Message Length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4825.0</td>\n",
       "      <td>4825.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>71.023627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>58.016023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>910.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_num  message_len\n",
       "count     4825.0  4825.000000\n",
       "mean         0.0    71.023627\n",
       "std          0.0    58.016023\n",
       "min          0.0     2.000000\n",
       "25%          0.0    33.000000\n",
       "50%          0.0    52.000000\n",
       "75%          0.0    92.000000\n",
       "max          0.0   910.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label=='ham'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>747.0</td>\n",
       "      <td>747.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>138.866131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29.183082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>132.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>157.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>224.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_num  message_len\n",
       "count      747.0   747.000000\n",
       "mean         1.0   138.866131\n",
       "std          0.0    29.183082\n",
       "min          1.0    13.000000\n",
       "25%          1.0   132.500000\n",
       "50%          1.0   149.000000\n",
       "75%          1.0   157.000000\n",
       "max          1.0   224.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label=='spam'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Woah! 910 characters, let's use masking to find this message(ham msg):\n",
    "\n",
    "df[df.message_len == 910]['message'][1084]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Takes in a string of text, then performs the following:\n",
    "#     1. Remove all punctuation\n",
    "#     2. Remove all stopwords\n",
    "#     3. Returns a list of the cleaned text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    STOPWORDS = stopwords.words('english') + ['u', 'ü', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure']\n",
    "    \n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return ' '.join([word.lower() for word in nopunc.split() if word.lower() not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0   \n",
       "1   ham                      Ok lar... Joking wif u oni...          0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "3   ham  U dun say so early hor... U c already then say...          0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "\n",
       "   message_len  \n",
       "0          111  \n",
       "1           29  \n",
       "2          155  \n",
       "3           49  \n",
       "4           61  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's \"tokenize\" these messages. Tokenization is just the term used to describe the process of converting the normal \n",
    "# text strings in to a list of tokens (words that we actually want)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>message_len</th>\n",
       "      <th>clean_msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>ok lar joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>dun say early hor c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0   \n",
       "1   ham                      Ok lar... Joking wif u oni...          0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "3   ham  U dun say so early hor... U c already then say...          0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "\n",
       "   message_len                                          clean_msg  \n",
       "0          111  go jurong point crazy available bugis n great ...  \n",
       "1           29                              ok lar joking wif oni  \n",
       "2          155  free entry wkly comp win fa cup final tkts 21s...  \n",
       "3           49                    dun say early hor c already say  \n",
       "4           61             nah think goes usf lives around though  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will remove punctuation or any stopword from the message\n",
    "df['clean_msg'] = df.message.apply(text_process)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('get', 303), ('ltgt', 276), ('ok', 272), ('go', 247), ('ill', 236), ('know', 232), ('got', 231), ('like', 229), ('call', 229), ('come', 224), ('good', 222), ('time', 189), ('day', 187), ('love', 185), ('going', 167), ('want', 163), ('one', 162), ('home', 160), ('lor', 160), ('need', 156), ('sorry', 153), ('still', 146), ('see', 137), ('n', 134), ('later', 134), ('da', 131), ('r', 131), ('back', 129), ('think', 128), ('well', 126), ('today', 125), ('send', 123), ('tell', 121), ('cant', 118), ('ì', 117), ('hi', 117), ('take', 112), ('much', 112), ('oh', 111), ('night', 107), ('hey', 106), ('happy', 105), ('great', 100), ('way', 100), ('hope', 99), ('pls', 98), ('work', 96), ('wat', 95), ('thats', 94), ('dear', 94)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words_ham = df[df.label=='ham'].clean_msg.apply(lambda x: x.split())\n",
    "# words\n",
    "ham_words = Counter()\n",
    "\n",
    "for msg in words_ham:\n",
    "    ham_words.update(msg)\n",
    "    \n",
    "print(ham_words.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('call', 347), ('free', 216), ('txt', 150), ('mobile', 123), ('text', 120), ('claim', 113), ('stop', 113), ('reply', 101), ('prize', 92), ('get', 83), ('new', 69), ('send', 67), ('nokia', 65), ('urgent', 63), ('cash', 62), ('win', 60), ('contact', 56), ('service', 55), ('please', 52), ('guaranteed', 50), ('customer', 49), ('16', 49), ('week', 49), ('tone', 48), ('per', 46), ('phone', 45), ('18', 43), ('chat', 42), ('awarded', 38), ('draw', 38), ('latest', 36), ('å£1000', 35), ('line', 35), ('150ppm', 34), ('mins', 34), ('receive', 33), ('camera', 33), ('1', 33), ('every', 33), ('message', 32), ('holiday', 32), ('landline', 32), ('shows', 31), ('å£2000', 31), ('go', 31), ('box', 30), ('number', 30), ('apply', 29), ('code', 29), ('live', 29)]\n"
     ]
    }
   ],
   "source": [
    "words_spam = df[df.label=='spam'].clean_msg.apply(lambda x: x.split())\n",
    "\n",
    "# words\n",
    "spam_words = Counter()\n",
    "\n",
    "for msg in words_spam:\n",
    "    spam_words.update(msg)\n",
    "    \n",
    "print(spam_words.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector \n",
    "# that machine learning models can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179,)\n",
      "(1393,)\n",
      "(4179,)\n",
      "(1393,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = df.clean_msg\n",
    "y = df.label_num\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (4179, 7996)\n",
      "<class 'scipy.sparse.csr.csr_matrix'> (1393, 7996)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# examine the document-term matrix\n",
    "print(type(X_train_dtm), X_train_dtm.shape)\n",
    "\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(type(X_test_dtm), X_test_dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7996 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 34796 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit_transform(X_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.9827709978463748\n",
      "\n",
      "\n",
      "=======Confision Matrix===========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1205,    8],\n",
       "       [  16,  164]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confision Matrix===========\")\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418    madamregret disturbancemight receive reference...\n",
       "4598                                laid airtel line rest\n",
       "386                                   customer place call\n",
       "1289    heygreat dealfarm tour 9am 5pm 95pax 50 deposi...\n",
       "5094    hi shanilrakhesh herethanksi exchanged uncut d...\n",
       "494                                      free nowcan call\n",
       "759     call youcarlos isare phones vibrate acting mig...\n",
       "3140                                  customer place call\n",
       "Name: clean_msg, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for false positives (ham incorrectly classifier)\n",
    "X_test[(y_pred_class==1) & (y_test==0)]\n",
    "# prediction is they are spam messages when they are not spam \n",
    "# X_test[y_pred_class > y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4674    hi babe chloe r smashed saturday night great w...\n",
       "3528    xmas new years eve tickets sale club day 10am ...\n",
       "3417    life never much fun great came made truly spec...\n",
       "2773    come takes little time child afraid dark becom...\n",
       "1960    guess somebody know secretly fancies wanna fin...\n",
       "5       freemsg hey darling 3 weeks word back id like ...\n",
       "2078                         85233 freeringtonereply real\n",
       "1457    claire havin borin time alone wanna cum 2nite ...\n",
       "190     unique enough find 30th august wwwareyouunique...\n",
       "2429    guess ithis first time created web page wwwasj...\n",
       "3057    unsubscribed services get tons sexy babes hunk...\n",
       "1021    guess somebody know secretly fancies wanna fin...\n",
       "4067    tbspersolvo chasing us since sept forå£38 defi...\n",
       "3358         sorry missed call lets talk time 07090201529\n",
       "2821    romcapspam everyone around responding well pre...\n",
       "2247    back work 2morro half term c 2nite sexy passio...\n",
       "Name: clean_msg, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction is they are non-spam messages when they are spam\n",
    "# print message text for false negatives (spam incorrectly classifier)\n",
    "X_test[y_pred_class < y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.11903975e-02, 3.97831612e-04, 1.06470895e-03, ...,\n",
       "       1.31939653e-02, 9.99821127e-05, 6.04083365e-06])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "# y_pred_prob.shape\n",
    "# X_test_dtm.shape\n",
    "y_pred_prob\n",
    "# doubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774342768159751"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.9669777458722182\n",
      "=======Confusion Matrix===========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1213,    0],\n",
       "       [  46,  134]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('bow', CountVectorizer()), \n",
    "                 ('tfid', TfidfTransformer()),  \n",
    "                 ('model', MultinomialNB())])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confusion Matrix===========\")\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import an instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# For small to medium-sized datasets, the 'liblinear' solver is a good choice. \n",
    "# It is suitable for both binary and multiclass problems and can handle L1 and L2 regularization.\n",
    "\n",
    "\n",
    "\n",
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01694418, 0.0152182 , 0.08261755, ..., 0.02198942, 0.00531726,\n",
       "       0.00679188])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "\n",
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======Accuracy Score===========\n",
      "0.9842067480258435\n",
      "\n",
      "\n",
      "=======Confision Matrix===========\n",
      "[[1213    0]\n",
      " [  22  158]]\n",
      "\n",
      "\n",
      "=======ROC AUC Score===========\n",
      "0.9835714940001832\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "print(\"\\n\")\n",
    "# print the confusion matrix\n",
    "print(\"=======Confision Matrix===========\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))\n",
    "print(\"\\n\")\n",
    "# calculate AUC\n",
    "print(\"=======ROC AUC Score===========\")\n",
    "print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->stop_words: string {'english'}, list, or None (default)\n",
    "        If 'english', a built-in stop word list for English is used.\n",
    "        If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "        If None, no stop words will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->ngram_range: tuple (min_n, max_n), default=(1, 1)\n",
    "        The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "        All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "# both min, max is included"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--> max_df: float in range [0.0, 1.0] or int, default=1.0\n",
    "        When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold(corpus-specific stop words).\n",
    "        If float, the parameter represents a proportion of documents.\n",
    "        If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-->min_df: float in range [0.0, 1.0] or int, default=1\n",
    "        When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "        If float, the parameter represents a proportion of documents.\n",
    "        If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
